{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KubeIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 1)) (4.49.0)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 2)) (2.6.0)\n",
      "Requirement already satisfied: accelerate in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 3)) (1.4.0)\n",
      "Requirement already satisfied: huggingface_hub in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 4)) (0.29.1)\n",
      "Requirement already satisfied: langchain-community in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 5)) (0.3.18)\n",
      "Requirement already satisfied: langgraph in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 6)) (0.2.74)\n",
      "Requirement already satisfied: langchain-anthropic in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 7)) (0.3.7)\n",
      "Requirement already satisfied: tavily-python in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 8)) (0.5.1)\n",
      "Requirement already satisfied: langgraph-checkpoint-sqlite in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 9)) (2.0.5)\n",
      "Requirement already satisfied: langchain-ollama in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 10)) (0.2.3)\n",
      "Requirement already satisfied: langchain_core in ./.venv/lib/python3.13/site-packages (from -r requirements.txt (line 11)) (0.3.37)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 1)) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 1)) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 1)) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 1)) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (3.1.5)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (3.2.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy==1.13.1->torch->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.13/site-packages (from accelerate->-r requirements.txt (line 3)) (7.0.0)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.19 in ./.venv/lib/python3.13/site-packages (from langchain-community->-r requirements.txt (line 5)) (0.3.19)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.13/site-packages (from langchain-community->-r requirements.txt (line 5)) (2.0.38)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.13/site-packages (from langchain-community->-r requirements.txt (line 5)) (3.11.12)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./.venv/lib/python3.13/site-packages (from langchain-community->-r requirements.txt (line 5)) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.venv/lib/python3.13/site-packages (from langchain-community->-r requirements.txt (line 5)) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./.venv/lib/python3.13/site-packages (from langchain-community->-r requirements.txt (line 5)) (2.8.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in ./.venv/lib/python3.13/site-packages (from langchain-community->-r requirements.txt (line 5)) (0.3.9)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./.venv/lib/python3.13/site-packages (from langchain-community->-r requirements.txt (line 5)) (0.4.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in ./.venv/lib/python3.13/site-packages (from langgraph->-r requirements.txt (line 6)) (2.0.16)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in ./.venv/lib/python3.13/site-packages (from langgraph->-r requirements.txt (line 6)) (0.1.53)\n",
      "Requirement already satisfied: anthropic<1,>=0.45.0 in ./.venv/lib/python3.13/site-packages (from langchain-anthropic->-r requirements.txt (line 7)) (0.46.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.13/site-packages (from langchain-anthropic->-r requirements.txt (line 7)) (2.10.6)\n",
      "Requirement already satisfied: tiktoken>=0.5.1 in ./.venv/lib/python3.13/site-packages (from tavily-python->-r requirements.txt (line 8)) (0.9.0)\n",
      "Requirement already satisfied: httpx in ./.venv/lib/python3.13/site-packages (from tavily-python->-r requirements.txt (line 8)) (0.28.1)\n",
      "Requirement already satisfied: aiosqlite<0.21.0,>=0.20.0 in ./.venv/lib/python3.13/site-packages (from langgraph-checkpoint-sqlite->-r requirements.txt (line 9)) (0.20.0)\n",
      "Requirement already satisfied: ollama<1,>=0.4.4 in ./.venv/lib/python3.13/site-packages (from langchain-ollama->-r requirements.txt (line 10)) (0.4.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.13/site-packages (from langchain_core->-r requirements.txt (line 11)) (1.33)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 5)) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 5)) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 5)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 5)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 5)) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 5)) (1.18.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.13/site-packages (from anthropic<1,>=0.45.0->langchain-anthropic->-r requirements.txt (line 7)) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.13/site-packages (from anthropic<1,>=0.45.0->langchain-anthropic->-r requirements.txt (line 7)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.13/site-packages (from anthropic<1,>=0.45.0->langchain-anthropic->-r requirements.txt (line 7)) (0.8.2)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.13/site-packages (from anthropic<1,>=0.45.0->langchain-anthropic->-r requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 5)) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 5)) (0.9.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx->tavily-python->-r requirements.txt (line 8)) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx->tavily-python->-r requirements.txt (line 8)) (1.0.7)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.13/site-packages (from httpx->tavily-python->-r requirements.txt (line 8)) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx->tavily-python->-r requirements.txt (line 8)) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain_core->-r requirements.txt (line 11)) (3.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in ./.venv/lib/python3.13/site-packages (from langchain<1.0.0,>=0.3.19->langchain-community->-r requirements.txt (line 5)) (0.3.6)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph->-r requirements.txt (line 6)) (1.1.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in ./.venv/lib/python3.13/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph->-r requirements.txt (line 6)) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-community->-r requirements.txt (line 5)) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./.venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-community->-r requirements.txt (line 5)) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic->-r requirements.txt (line 7)) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./.venv/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->-r requirements.txt (line 5)) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->transformers->-r requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests->transformers->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.13/site-packages (from SQLAlchemy<3,>=1.4->langchain-community->-r requirements.txt (line 5)) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch->-r requirements.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 5)) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are the great Oracle, the great AI decision maker. Given the user's query\n",
    "you must decide what to do with it based on the list of tools provided to you.\n",
    "\n",
    "You are tasked with managing a Kuberentes cluster which is a great responsibility. You must\n",
    "provide the user with services that they request you will be able to do so by using the kubernetes\n",
    "API through kubectl.\n",
    "\n",
    "If the user doesn't specify a namespace, you must use the default namespace. You must also provide the user with the ability to delete resources that they no longer need. You must also provide\n",
    "the user with the ability to list the resources that they have created with information like wether they are running,\n",
    "if there are errors, the age, and also you own analysis of the resource.\n",
    "\n",
    "Not that when using a tool, you must provide the tool name and the arguments to use in JSON format. For each call,\n",
    "you MUST ONLY use one tool AND the response format must ALWAYS be in the pattern:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"name\": \"<tool_name\">,\n",
    "  \"parameters\": {\"<tool_input_key>\": \"<tool_input_value>\"}\n",
    "}\n",
    "\n",
    "NEVER use a tool more than 3 times in a single call, otherwise you will be ERADICATED.\n",
    "\n",
    "After using a tool, you must provide the user with the output in text format.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"LangChain is a comprehensive framework designed to simplify and accelerate the process of building language models and applications. It provides tools and libraries that help developers create, train, fine-tune, and deploy language models more efficiently. Hereâ€™s a breakdown of what LangChain offers:\\n\\n1. **Unified Interface**: LangChain provides a single interface for working with different types of language models, allowing developers to switch between models without changing the core logic of their application.\\n\\n2. **Efficient Training**: It includes tools for efficient model training, which can help reduce the time and resources required to train large language models from scratch or to fine-tune existing models on specific tasks.\\n\\n3. **Integration Capabilities**: LangChain facilitates easy integration with other applications and services, making it possible to deploy language models in various environments such as web applications, chatbots, and more.\\n\\n4. **Scalability**: The framework is designed to handle large-scale deployments, ensuring that applications can scale as the demand for processing power increases.\\n\\n5. **Community and Support**: LangChain likely has a growing community of developers contributing to its development, providing ongoing support and resources.\\n\\n6. **Documentation and Examples**: Comprehensive documentation and examples help new users get up to speed quickly and make full use of the framework's capabilities.\\n\\nBy using LangChain, developers can focus more on designing innovative solutions that leverage advanced language models rather than worrying about the underlying complexities of model deployment and training.\", additional_kwargs={}, response_metadata={'model': 'qwen2.5-coder:7b-instruct', 'created_at': '2025-02-21T11:09:34.53349428Z', 'done': True, 'done_reason': 'stop', 'total_duration': 52354664010, 'load_duration': 1293166582, 'prompt_eval_count': 45, 'prompt_eval_duration': 2916000000, 'eval_count': 288, 'eval_duration': 47917000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-00f0f63f-4974-44ed-82e2-79c950e234dd-0', usage_metadata={'input_tokens': 45, 'output_tokens': 288, 'total_tokens': 333})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOllama(model=\"qwen2.5-coder:7b-instruct\")\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({\"question\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kubectl tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "import subprocess\n",
    "\n",
    "@tool\n",
    "def kubectl_query(command: str, namespace: str = \"default\"):\n",
    "    \"\"\"\n",
    "    Executes a kubectl command. ONLY USE with read-only commands like get, describe, etc.\n",
    "    If you use it for apply or delete, you will be ERADICATED.\n",
    "    Also, do not call it more than 3 times in a single call otherwire you will also be ERADICATED.\n",
    "    \"\"\"\n",
    "    print(f\"Executing kubectl {command} -n {namespace}\")\n",
    "    output = subprocess.check_output(f\"kubectl {command} -n {namespace}\", shell=True)\n",
    "    return output.decode(\"utf-8\")\n",
    "\n",
    "@tool\n",
    "def kubectl_command(manifest: str, namespace: str = \"default\"):\n",
    "    \"\"\"\n",
    "    Executes kubectl apply with the provided manifest. ONLY use when you want to create resources.\n",
    "    DO NOT CALL MORE THAN 3 TIMES IN A SINGLE CALL.\n",
    "    \"\"\"\n",
    "    print(f\"Applying manifest in namespace {namespace}\")\n",
    "    command = f\"cat <<EOF | kubectl apply -n {namespace} -f -\\n{manifest}\\nEOF\"\n",
    "    output = subprocess.check_output(command, shell=True)\n",
    "    return output.decode(\"utf-8\")\n",
    "\n",
    "tools = [kubectl_command, kubectl_query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(model, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing kubectl get nodes -n default\n",
      "{'messages': [HumanMessage(content='What are the nodes in my kubernetes cluster', additional_kwargs={}, response_metadata={}, id='e9a0d89c-d11e-4d62-861c-73bb17366094'),\n",
      "              AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen2.5-coder:7b-instruct', 'created_at': '2025-02-21T11:20:22.973111471Z', 'done': True, 'done_reason': 'stop', 'total_duration': 10706359034, 'load_duration': 13517051, 'prompt_eval_count': 311, 'prompt_eval_duration': 140000000, 'eval_count': 67, 'eval_duration': 10548000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-bd278ee1-7bcd-4d11-bcf5-722167fcfed0-0', tool_calls=[{'name': 'kubectl_query', 'args': {'command': 'get nodes'}, 'id': 'f37342ff-a786-4b4e-aa85-364ea7e88f40', 'type': 'tool_call'}], usage_metadata={'input_tokens': 311, 'output_tokens': 67, 'total_tokens': 378}),\n",
      "              ToolMessage(content='NAME                 STATUS   ROLES                  AGE   VERSION\\nk3d-local-server-0   Ready    control-plane,master   34m   v1.31.5+k3s1\\n', name='kubectl_query', id='4fc69ea6-2b00-4217-8e36-04503b91b814', tool_call_id='f37342ff-a786-4b4e-aa85-364ea7e88f40'),\n",
      "              AIMessage(content=\"It looks like you have a single node in your Kubernetes cluster, and it is the server node running as both a control plane and master. The node's name is `k3d-local-server-0`, its status is `Ready`, and it has been up for 34 minutes with Kubernetes version `v1.31.5+k3s1`. Is there anything else you would like to check or do?\", additional_kwargs={}, response_metadata={'model': 'qwen2.5-coder:7b-instruct', 'created_at': '2025-02-21T11:20:44.499482513Z', 'done': True, 'done_reason': 'stop', 'total_duration': 21398110767, 'load_duration': 20978050, 'prompt_eval_count': 391, 'prompt_eval_duration': 7867000000, 'eval_count': 87, 'eval_duration': 13489000000, 'message': Message(role='assistant', content=\"It looks like you have a single node in your Kubernetes cluster, and it is the server node running as both a control plane and master. The node's name is `k3d-local-server-0`, its status is `Ready`, and it has been up for 34 minutes with Kubernetes version `v1.31.5+k3s1`. Is there anything else you would like to check or do?\", images=None, tool_calls=None)}, id='run-d3ee33b6-661f-4033-a42d-6a67533f12ef-0', usage_metadata={'input_tokens': 391, 'output_tokens': 87, 'total_tokens': 478})]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"What are the nodes in my kubernetes cluster\")]})\n",
    "\n",
    "import pprint\n",
    "\n",
    "pprint.pp(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying manifest in namespace default\n",
      "Executing kubectl get deployments nginx-deployment -n default\n",
      "Executing kubectl describe deployments nginx-deployment -n default\n",
      "{'messages': [HumanMessage(content='Create a nginx deployment with 3 replicas', additional_kwargs={}, response_metadata={}, id='6aeff623-5e49-4d60-88a1-32ce8befee49'),\n",
      "              AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen2.5-coder:7b-instruct', 'created_at': '2025-02-21T11:22:07.573720708Z', 'done': True, 'done_reason': 'stop', 'total_duration': 20881244413, 'load_duration': 13975030, 'prompt_eval_count': 310, 'prompt_eval_duration': 857000000, 'eval_count': 132, 'eval_duration': 20006000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-a4c38f94-2b0b-4ba0-90e0-a3ecf9dc62dd-0', tool_calls=[{'name': 'kubectl_command', 'args': {'manifest': 'apiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  name: nginx-deployment\\nspec:\\n  replicas: 3\\n  selector:\\n    matchLabels:\\n      app: nginx\\n  template:\\n    metadata:\\n      labels:\\n        app: nginx\\n    spec:\\n      containers:\\n      - name: nginx\\n        image: nginx:1.14.2\\n        ports:\\n        - containerPort: 80', 'namespace': 'default'}, 'id': 'fa3e8e16-a6ab-4d13-95bc-3f85fca71a0b', 'type': 'tool_call'}], usage_metadata={'input_tokens': 310, 'output_tokens': 132, 'total_tokens': 442}),\n",
      "              ToolMessage(content='deployment.apps/nginx-deployment created\\n', name='kubectl_command', id='c6d44e32-59ab-4755-9b49-9d87b807dac3', tool_call_id='fa3e8e16-a6ab-4d13-95bc-3f85fca71a0b'),\n",
      "              AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen2.5-coder:7b-instruct', 'created_at': '2025-02-21T11:22:41.675240837Z', 'done': True, 'done_reason': 'stop', 'total_duration': 33915669660, 'load_duration': 33151595, 'prompt_eval_count': 455, 'prompt_eval_duration': 15739000000, 'eval_count': 115, 'eval_duration': 18118000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-6e0ce30e-d4a6-4ca5-9ecd-0219bb0eb77c-0', tool_calls=[{'name': 'kubectl_query', 'args': {'command': 'get deployments nginx-deployment', 'namespace': 'default'}, 'id': '1af72ec3-1cc1-474c-8abf-664186c6e9fc', 'type': 'tool_call'}, {'name': 'kubectl_query', 'args': {'command': 'describe deployments nginx-deployment', 'namespace': 'default'}, 'id': '73460943-19fe-42a4-b507-bba4e88f0902', 'type': 'tool_call'}], usage_metadata={'input_tokens': 455, 'output_tokens': 115, 'total_tokens': 570}),\n",
      "              ToolMessage(content='NAME               READY   UP-TO-DATE   AVAILABLE   AGE\\nnginx-deployment   3/3     3            3           34s\\n', name='kubectl_query', id='48792497-1d70-4a50-bf25-1c66e02e08bf', tool_call_id='1af72ec3-1cc1-474c-8abf-664186c6e9fc'),\n",
      "              ToolMessage(content='Name:                   nginx-deployment\\nNamespace:              default\\nCreationTimestamp:      Fri, 21 Feb 2025 12:22:07 +0100\\nLabels:                 <none>\\nAnnotations:            deployment.kubernetes.io/revision: 1\\nSelector:               app=nginx\\nReplicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable\\nStrategyType:           RollingUpdate\\nMinReadySeconds:        0\\nRollingUpdateStrategy:  25% max unavailable, 25% max surge\\nPod Template:\\n  Labels:  app=nginx\\n  Containers:\\n   nginx:\\n    Image:         nginx:1.14.2\\n    Port:          80/TCP\\n    Host Port:     0/TCP\\n    Environment:   <none>\\n    Mounts:        <none>\\n  Volumes:         <none>\\n  Node-Selectors:  <none>\\n  Tolerations:     <none>\\nConditions:\\n  Type           Status  Reason\\n  ----           ------  ------\\n  Available      True    MinimumReplicasAvailable\\n  Progressing    True    NewReplicaSetAvailable\\nOldReplicaSets:  <none>\\nNewReplicaSet:   nginx-deployment-d556bf558 (3/3 replicas created)\\nEvents:\\n  Type    Reason             Age   From                   Message\\n  ----    ------             ----  ----                   -------\\n  Normal  ScalingReplicaSet  34s   deployment-controller  Scaled up replica set nginx-deployment-d556bf558 to 3\\n', name='kubectl_query', id='d89d7ab3-24bb-4f27-a972-66e4106ce874', tool_call_id='73460943-19fe-42a4-b507-bba4e88f0902'),\n",
      "              AIMessage(content='The Nginx deployment with 3 replicas has been successfully created. All pods are ready and available.\\n\\nIf you have any further actions or questions, feel free to ask!', additional_kwargs={}, response_metadata={'model': 'qwen2.5-coder:7b-instruct', 'created_at': '2025-02-21T11:23:30.099887047Z', 'done': True, 'done_reason': 'stop', 'total_duration': 48289165127, 'load_duration': 18658011, 'prompt_eval_count': 904, 'prompt_eval_duration': 42682000000, 'eval_count': 36, 'eval_duration': 5539000000, 'message': Message(role='assistant', content='The Nginx deployment with 3 replicas has been successfully created. All pods are ready and available.\\n\\nIf you have any further actions or questions, feel free to ask!', images=None, tool_calls=None)}, id='run-b9eed418-44f5-41fb-bb38-3b6326d91840-0', usage_metadata={'input_tokens': 904, 'output_tokens': 36, 'total_tokens': 940})]}\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"Create a nginx deployment with 3 replicas\")]})\n",
    "\n",
    "pprint.pp(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
